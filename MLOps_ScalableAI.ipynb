{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcA6M0c67Cb4weDQXzyf6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jitria/MLOps_ScalableAI/blob/main/MLOps_ScalableAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QeI-o0jk_W1p",
        "outputId": "41ff0ef9-75f9-4214-c2fb-4e9fe23c83ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate>=0.30.0 in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.18.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.11.10)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from deepspeed) (13.580.82)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.30.0) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.30.0) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.30.0) (3.0.3)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.18.2-py3-none-any.whl size=1763310 sha256=4b15c54f177e19ff29b2b6facfa0331ccba7d3c1b4392dff1b7c964d3c9d5651\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/ad/2e/e03d4739ddc0417efd8a120c2b9e784005aa226037e558c163\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, pyarrow, ninja, mpi4py, wandb, deepspeed, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.22.3\n",
            "    Uninstalling wandb-0.22.3:\n",
            "      Successfully uninstalled wandb-0.22.3\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 deepspeed-0.18.2 hjson-3.1.0 mpi4py-4.1.1 ninja-1.13.0 pyarrow-22.0.0 wandb-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"transformers>=4.40.0\" \"accelerate>=0.30.0\" deepspeed datasets wandb mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "import wandb\n",
        "\n",
        "os.environ[\"WANDB_ENTITY\"] = \"dankook\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"MLOps_ScalableAI\"\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"deepspeed_bert_imdb_colab\"\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R5eqzjb2_4Dq",
        "outputId": "80bbeeb5-a6b6-48d6-d536-ef3976b3abe7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find deepspeed_bert_imdb_colab.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimjs62501569\u001b[0m (\u001b[33mdankook\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb = load_dataset(\"imdb\")\n",
        "imdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "415acc2932a54393858d2eb597473d75",
            "a2c055c96126421c8006bd14a2e08438",
            "1e956af634704b498831ab7a9f3ee150",
            "a5b1c48e5c644fb58fa03ca3552fcb4a",
            "b9386c8bb6fe4b8eb4e4104ee9523712",
            "e7e27a87b69c44148be72c0f1ca1c1db",
            "dab3fff57e5d4c1e9ff5c48f5af1af10",
            "a34fb5c43f48400b8b381f2e2aad893c",
            "d1c8b8ecd4494bfeba9901e894273fa1",
            "f11780af55c2490b878dc19cc62122bd",
            "0e42a572775a46de86c7f3357e8f0add",
            "200a424f7bf84f39833533b2252f0fdd",
            "f35de3cac4d945ec919b2664f8bad43d",
            "78824f54c4be42a8920864474269b300",
            "f6a221ece5ce45fab7cc507ea1db5495",
            "7201605a321943f2ae05230325e398fc",
            "7b4d6b5645d544b9b825f88047f63dfb",
            "696f5422efaa4aa8941a000b9ee653bb",
            "6710315a91d3400a8deb6717a227ae09",
            "3f578f8de9c84f00a324d7057cdfc728",
            "c9d79a9056c147c5ba4c1e5aa2c54b98",
            "f87cb63143144bed80b0806e51a2740c",
            "29208fe607a54399a1fcd3da4f62c59b",
            "493d621c8b494e64bddc81b0d919338c",
            "0ba313b89c434de68d0ad46f07649432",
            "5a6f2ab92cf042c599244671e20873b9",
            "70b0a9b4a8c94b4a941fda695972fe03",
            "b9acf8352db34615bd43c0f347747bdf",
            "b909e78114a741c7959b34b69290f214",
            "b509a9a6cee44084819bbe4a95badb56",
            "bc55fe7a8b2642ccbde5267d8c39f2c7",
            "5c9fe26747a4441e8cfb9977add73ca5",
            "5c9cb6ea9d3648afb2e3cd9577c5927d",
            "59671d3f154247bb9643f315e30c3359",
            "422741a2891f4a47a348006be38fa9ff",
            "c81ada038f444633ad89a2f4331d7ce5",
            "83213e7d15c34b1ab69bd7b5a68b039f",
            "1c2cab79ab00481eb16660ecca040da3",
            "c84c0e544dc449c5b270a3dd56575619",
            "1cfecd3b36db446b8da02c71fb1bb71a",
            "e047afe2bd684d539cee0543028d51af",
            "cce79279dc324c3a9e766a9897961994",
            "ae56bf1b33224cef86199ca3facf083c",
            "427804e332d0449a82216ea872796ce0",
            "48eda1d3d0e64c8a939df388eed0b392",
            "8b8e89eefbd84627801eca66472573c7",
            "42e3a6fac6a94916a73c7daf1aa912c0",
            "26a4a7e9101d4b97a799ca0d2cbe9063",
            "d84a70465c7e4a909ad77a741554422d",
            "29031598f4ec46559486c0b42a1b0aab",
            "8533df2257d74c4898a01ca450d0b246",
            "f7a329c1833740c2a9f2577a19c15795",
            "f1ac468da5334debbeca7e2d67f06a60",
            "f1e0d62521f344208e9581e57758607b",
            "e14a803117cf45cbaf89820ebad6e9a3",
            "572e8d81ae634f728b3f9ab2ef880981",
            "4399a17b8d3941d3871fd1700e8d894d",
            "613d98cdfaf3418ea56d7eeb704db80d",
            "b7609007c9f948a2977d93fa169db07c",
            "12f0128275de412c80046df032a05f67",
            "074e33628e27438e9c6cbfbdeb1df466",
            "4f5627d01eb84a57aed256d9d69de53e",
            "aff007f2fe4d4305997f12802f414449",
            "5980d5931cc04c32a9b1c028596f0972",
            "6d0106643ef44a749b67f25a923dfbe1",
            "d794be7127f944699c29ea7a86388697",
            "74bbc631a5604780ae3583e97d56e759",
            "380dea7351aa4ee6bc6eccd00e8593bf",
            "919c8f46496849069ec11d4e8d6ebebf",
            "246c00170ca9443bb6029f1cf7ce31cd",
            "869af7ed884f4a33b185c48488f3fab5",
            "a0fa8c3e62604956863d856e648eec27",
            "31b73540ecc342ffb93db3f61f1abcd8",
            "754d99cee94e4a0b98d49485bf1adec8",
            "5807886dc8df4375a03d0b7304640c16",
            "e7a9d0f5941346909fecb44f6cbf94ab",
            "ab7de14b82b14f48ae202bbadecdecbe"
          ]
        },
        "collapsed": true,
        "id": "qUqI-gh5_4Au",
        "outputId": "b2849057-1cb4-4d40-fc49-c9e681aebdee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "415acc2932a54393858d2eb597473d75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "200a424f7bf84f39833533b2252f0fdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29208fe607a54399a1fcd3da4f62c59b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59671d3f154247bb9643f315e30c3359"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48eda1d3d0e64c8a939df388eed0b392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572e8d81ae634f728b3f9ab2ef880981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74bbc631a5604780ae3583e97d56e759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "    )\n",
        "\n",
        "encoded_imdb = imdb.map(preprocess_function, batched=True)\n",
        "encoded_imdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "c041bddb11854206b6f757d9ce131822",
            "939089c2719c4225962ef9a6de7747ba",
            "16ae1dd6d36f41a9abd746b90c1a044b",
            "2ac92a0ad2ef4eecbbf08642dd0cbadc",
            "e7da74123c514bf6aebbe03aa3bdd77a",
            "b1891db329e448118844c17fe23c8c80",
            "dc4959e94d2c476aa29978494a73a249",
            "af101f84d4ce4ef1952156766d188292",
            "e302846f796f434a8df3eca6a8e2b3c6",
            "1f11ba3cdf7f4fef8950a55b55490f71",
            "646f4bad427e4a4e9f29dd5fd838b4ca",
            "4788852c29b64b2f811adad1b0288d13",
            "26b4a66261a147f9ad4ad94237007beb",
            "2fa47d91dc2845d99d689c010e5eaf86",
            "cb37f77b81ed4a388f0b4f6bf11c01b5",
            "17fc98c884af40da8720f8bba053d62e",
            "0d834899afb74a04b8d4a46804bd26db",
            "3c0d001eee514818a772f9234e3a40d6",
            "a71819a0add24007b8ede7f33a293f73",
            "f1c64d761af0480fa082103097b25e38",
            "d83d0e5296c8420e892e8a96f8e3dc1e",
            "e2f8b1817717412baa9e585ebb04e5d9",
            "7b75c9d438824e1fb73c50c33dbe077d",
            "b0c4346383704a6bbc16f50d2b2b1729",
            "66d9074212624382b6a814ba6fc805e5",
            "1418a814e18948a090a89b6453cf6d88",
            "12d24e9463fc48e591f5053f35eebad1",
            "1957e4a5b2be4139823306ed1daf834b",
            "04672a3e0e5b482b970b0276297bb05f",
            "b8940ccd85064e78ade8ea9d0782d18d",
            "4298ef09d4a24603837ad4e58f86b013",
            "98241066af07434f98137ceefb0a6da3",
            "e3339d036ad745128c8df796964fb54b",
            "b623f826920641649922bdd37655c88f",
            "0dcacd7b24c04f2c8baefae4181280fc",
            "b63524c64c914be09c54ffe07ce3053a",
            "e3e4746f2ae74076be0c116576a5c4e4",
            "cf4dfd1080544a88bf4bc38c0b5d96e4",
            "22e1449186b5425995a092dc83c36319",
            "2a55de88dc5e48158c8ea82a4a4216fb",
            "ebee7939356a4c7e90d362848b30644f",
            "8378ca7334634247a28c14fdd2f4963d",
            "baadf6d822c54a39bb2f133761d641bd",
            "775afd5963804eb8b4dada31b0846466",
            "85b8f77bd64f469c95abdb3008796166",
            "f0898c8a771348dfa0aaae9eee8c8143",
            "ccab173d2cb4437197c33b6cc5709008",
            "2ba28bd2dbb64d509eb8ac908f4da555",
            "f96c1c08cb9c4d839cb4c5b6ee3afc35",
            "3f5f9fd28b9b4351b90139c776db388d",
            "f34e5eea8c5946898e6e6dd8cfc1688e",
            "5380c8f8e3ca4ae4ae943c297ad745eb",
            "d5e4d030d29c435eb56e81cbffb46467",
            "4014b5b23fa045c5a05c86ee9797f01c",
            "71797b49c8c144db9327a040702f31b8",
            "9a42cbeedb044d63954c44a3dc264e23",
            "f95d08bfa59743bfa608f4de1deadaad",
            "00302b8d31024a3789f23e90711288d6",
            "d99060653c1443478e6fef2b847875de",
            "ae4077f02b9a42a3a4f0615e2a6b3507",
            "817a4196b14147b08ad42c2079b82cb4",
            "e5096222ae604ebd956cbc260f1c882f",
            "945716a4a67d46af90f5dd123e5d3ec8",
            "8d4d351106b54338b668ebbfe0721233",
            "a67bc5c021dc4354a370366cafa3bfa4",
            "1d50e3057a6c4bb8b57da5271e8e4a62",
            "627b2d520d6b4404a626f0d927dc2e3c",
            "fa7209dbed8d4d7ca5e68532a7b457d4",
            "1d81532d99334de6a505434ee405da9e",
            "4d692bd1d0094fe2a4cea5bcaa341a17",
            "01c53fa837ff4785a111b736efc56986",
            "064645f5b7854a8d8b00b81a81165e55",
            "9262ef81c7224f0ebe8d702ddda8f4e1",
            "bd1ed1ec21e44ec380f336d11e879d29",
            "07dec522a5e94bda809a3f85d3cf0df7",
            "00502e3b384d48ffb9b7488ab838416d",
            "5978568298eb4c8baf513932f47461c0"
          ]
        },
        "id": "-KFTKV_f_394",
        "outputId": "7f76f3a1-9822-4a7e-85d8-db23e00cfeb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c041bddb11854206b6f757d9ce131822"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4788852c29b64b2f811adad1b0288d13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b75c9d438824e1fb73c50c33dbe077d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b623f826920641649922bdd37655c88f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85b8f77bd64f469c95abdb3008796166"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a42cbeedb044d63954c44a3dc264e23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "627b2d520d6b4404a626f0d927dc2e3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "\n",
        "num_labels = 2\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "70bab95dc9f946deb03fa5f9827a77ce",
            "83052e5576274e769072f30d894e3faa",
            "e63a7829b9694b6c9e7eac06bf01cd45",
            "137f0dfc7bbc4d73a3bd65fbfad138d3",
            "499bf2b38536489caed34f94361c884b",
            "0b3ad46b7595468abb53d33b0ac8fe8f",
            "7b54c81cb43343e1bbf3c9c14806f9ab",
            "081111bdc7bc4b2b8fa76463f67b874f",
            "d6fc876bd4644b8f8481706ce109a60b",
            "4afeb34257c94288942cdf15bf36799c",
            "dbc06f7ee9464bd2923146fab6abeed6"
          ]
        },
        "id": "rC6UVqqh_364",
        "outputId": "77af9d06-7dc3-4ca2-c5ef-007145125556"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70bab95dc9f946deb03fa5f9827a77ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    accuracy = (preds == labels).astype(np.float32).mean().item()\n",
        "    return {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "0OCsDvII_34E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "deepspeed_config = {\n",
        "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
        "    \"gradient_accumulation_steps\": \"auto\",\n",
        "    \"train_batch_size\": \"auto\",\n",
        "\n",
        "    \"fp16\": {\"enabled\": \"auto\"},\n",
        "\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "        \"offload_optimizer\": {\"device\": \"cpu\", \"pin_memory\": True},\n",
        "        \"offload_param\": {\"device\": \"cpu\", \"pin_memory\": True}\n",
        "    },\n",
        "\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"steps_per_print\": 2000\n",
        "}\n",
        "\n",
        "ds_config_path = \"ds_config_zero2_offload.json\"\n",
        "with open(ds_config_path, \"w\") as f:\n",
        "    json.dump(deepspeed_config, f, indent=2)\n",
        "\n",
        "print(\"Saved DeepSpeed config to\", ds_config_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REvmG-HL_31Z",
        "outputId": "b015bac6-8f4f-4dd6-be7d-1680b007add2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved DeepSpeed config to ds_config_zero2_offload.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./bert-imdb-deepspeed\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=[\"wandb\"],\n",
        "    run_name=\"bert-imdb-deepspeed-zero2-offload\",\n",
        "    deepspeed=ds_config_path,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_imdb[\"train\"],\n",
        "    eval_dataset=encoded_imdb[\"test\"].select(range(1000)),\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHorlIHB_3yl",
        "outputId": "e440bad2-32fb-42bb-8410-c32ca135a729"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2247407904.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pRwsMJ5Z_3vp",
        "outputId": "507e0bb8-236d-4485-e0e9-7d9e9b55062c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W1120 05:08:22.195000 1915 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W1120 05:08:22.195000 1915 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed CUDA version 12.5 does not match the version torch was compiled with 12.6 but since the APIs are compatible, accepting this combination\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251120_050926-0g6tqetj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dankook/MLOps_ScalableAI%20/runs/0g6tqetj' target=\"_blank\">bert-imdb-deepspeed-zero2-offload</a></strong> to <a href='https://wandb.ai/dankook/MLOps_ScalableAI%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dankook/MLOps_ScalableAI%20' target=\"_blank\">https://wandb.ai/dankook/MLOps_ScalableAI%20</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dankook/MLOps_ScalableAI%20/runs/0g6tqetj' target=\"_blank\">https://wandb.ai/dankook/MLOps_ScalableAI%20/runs/0g6tqetj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 45:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.565700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.319400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.353800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.358500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.282400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.340200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.313600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.285000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.313400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.322100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.300300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.284300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.279200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.300200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.232300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.331100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.293800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.276500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.278800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.275600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.241500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.256900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.242800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.304200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.270100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.200800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.286200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3125, training_loss=0.3024204151916504, metrics={'train_runtime': 2741.3675, 'train_samples_per_second': 9.12, 'train_steps_per_second': 1.14, 'total_flos': 3286573669941248.0, 'train_loss': 0.3024204151916504, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "sq4VW6kR1aRs",
        "outputId": "6d6e9e3c-514f-4280-b0ca-bce3d2ffa6ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:15]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2770470082759857, 'eval_accuracy': 0.9129999876022339, 'eval_runtime': 15.7415, 'eval_samples_per_second': 63.527, 'eval_steps_per_second': 7.941, 'epoch': 1.0}\n"
          ]
        }
      ]
    }
  ]
}